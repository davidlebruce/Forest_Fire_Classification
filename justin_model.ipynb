{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_regression,mutual_info_regression\n",
    "# for feature selection\n",
    "from sklearn.feature_selection import RFECV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.feature_selection import chi2, f_classif, mutual_info_classif\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_fire_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [df['stat_cause_descr'] == 'Missing/Undefined',\n",
    " df['stat_cause_descr'] == 'Arson',\n",
    " df['stat_cause_descr'] == 'Debris Burning',\n",
    " df['stat_cause_descr'] == 'Campfire',\n",
    " df['stat_cause_descr'] == 'Miscellaneous',\n",
    " df['stat_cause_descr'] == 'Fireworks',\n",
    " df['stat_cause_descr'] == 'Lightning',\n",
    " df['stat_cause_descr'] == 'Equipment Use',\n",
    " df['stat_cause_descr'] == 'Children',\n",
    " df['stat_cause_descr'] == 'Smoking',\n",
    " df['stat_cause_descr'] == 'Railroad',\n",
    " df['stat_cause_descr'] == 'Structure',\n",
    " df['stat_cause_descr'] == 'Powerline']\n",
    "outputs = range(0,(len(conditions)))\n",
    "df['stat_cause_descr'] = np.select(conditions, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\n",
    "    'Unnamed: 0',\n",
    "    'fire_size',\n",
    "    'fire_size_class',\n",
    "    'disc_clean_date'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=cols_to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stat_cause_descr</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>Temp_pre_30</th>\n",
       "      <th>Temp_pre_15</th>\n",
       "      <th>Temp_pre_7</th>\n",
       "      <th>Wind_pre_30</th>\n",
       "      <th>Wind_pre_15</th>\n",
       "      <th>Wind_pre_7</th>\n",
       "      <th>Hum_pre_30</th>\n",
       "      <th>Hum_pre_15</th>\n",
       "      <th>Hum_pre_7</th>\n",
       "      <th>Prec_pre_30</th>\n",
       "      <th>Prec_pre_15</th>\n",
       "      <th>Prec_pre_7</th>\n",
       "      <th>remoteness</th>\n",
       "      <th>target</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>temp_avg</th>\n",
       "      <th>is_remote</th>\n",
       "      <th>did_rain</th>\n",
       "      <th>Temp_pre_30_bin</th>\n",
       "      <th>Temp_pre_15_bin</th>\n",
       "      <th>Temp_pre_7_bin</th>\n",
       "      <th>discovery_month_Aug</th>\n",
       "      <th>discovery_month_Dec</th>\n",
       "      <th>discovery_month_Feb</th>\n",
       "      <th>discovery_month_Jan</th>\n",
       "      <th>discovery_month_Jul</th>\n",
       "      <th>discovery_month_Jun</th>\n",
       "      <th>discovery_month_Mar</th>\n",
       "      <th>discovery_month_May</th>\n",
       "      <th>discovery_month_Nov</th>\n",
       "      <th>discovery_month_Oct</th>\n",
       "      <th>discovery_month_Sep</th>\n",
       "      <th>state_AL</th>\n",
       "      <th>state_AR</th>\n",
       "      <th>state_AZ</th>\n",
       "      <th>state_CA</th>\n",
       "      <th>state_CO</th>\n",
       "      <th>state_CT</th>\n",
       "      <th>state_DE</th>\n",
       "      <th>state_FL</th>\n",
       "      <th>state_GA</th>\n",
       "      <th>state_HI</th>\n",
       "      <th>state_IA</th>\n",
       "      <th>state_ID</th>\n",
       "      <th>state_IL</th>\n",
       "      <th>state_IN</th>\n",
       "      <th>state_KS</th>\n",
       "      <th>state_KY</th>\n",
       "      <th>state_LA</th>\n",
       "      <th>state_MA</th>\n",
       "      <th>state_MD</th>\n",
       "      <th>state_ME</th>\n",
       "      <th>state_MI</th>\n",
       "      <th>state_MN</th>\n",
       "      <th>state_MO</th>\n",
       "      <th>state_MS</th>\n",
       "      <th>state_MT</th>\n",
       "      <th>state_NC</th>\n",
       "      <th>state_ND</th>\n",
       "      <th>state_NE</th>\n",
       "      <th>state_NH</th>\n",
       "      <th>state_NJ</th>\n",
       "      <th>state_NM</th>\n",
       "      <th>state_NV</th>\n",
       "      <th>state_NY</th>\n",
       "      <th>state_OH</th>\n",
       "      <th>state_OK</th>\n",
       "      <th>state_OR</th>\n",
       "      <th>state_PA</th>\n",
       "      <th>state_PR</th>\n",
       "      <th>state_RI</th>\n",
       "      <th>state_SC</th>\n",
       "      <th>state_SD</th>\n",
       "      <th>state_TN</th>\n",
       "      <th>state_TX</th>\n",
       "      <th>state_UT</th>\n",
       "      <th>state_VA</th>\n",
       "      <th>state_VT</th>\n",
       "      <th>state_WA</th>\n",
       "      <th>state_WI</th>\n",
       "      <th>state_WV</th>\n",
       "      <th>state_WY</th>\n",
       "      <th>Vegetation_4</th>\n",
       "      <th>Vegetation_9</th>\n",
       "      <th>Vegetation_12</th>\n",
       "      <th>Vegetation_14</th>\n",
       "      <th>Vegetation_15</th>\n",
       "      <th>Vegetation_16</th>\n",
       "      <th>longitude_bin</th>\n",
       "      <th>west_coast</th>\n",
       "      <th>very_windy_30</th>\n",
       "      <th>very_windy_15</th>\n",
       "      <th>very_windy_7</th>\n",
       "      <th>low_humid_30</th>\n",
       "      <th>low_humid_15</th>\n",
       "      <th>low_humid_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18.105072</td>\n",
       "      <td>-66.753044</td>\n",
       "      <td>76.065753</td>\n",
       "      <td>76.490462</td>\n",
       "      <td>76.824675</td>\n",
       "      <td>4.341807</td>\n",
       "      <td>3.492857</td>\n",
       "      <td>3.262092</td>\n",
       "      <td>78.216590</td>\n",
       "      <td>76.793750</td>\n",
       "      <td>76.381579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017923</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2007</td>\n",
       "      <td>76.460297</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>35.038330</td>\n",
       "      <td>-87.610000</td>\n",
       "      <td>45.596180</td>\n",
       "      <td>44.618000</td>\n",
       "      <td>32.618353</td>\n",
       "      <td>2.709764</td>\n",
       "      <td>2.881707</td>\n",
       "      <td>1.976471</td>\n",
       "      <td>70.840000</td>\n",
       "      <td>65.858911</td>\n",
       "      <td>55.505882</td>\n",
       "      <td>59.8</td>\n",
       "      <td>8.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.184355</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2006</td>\n",
       "      <td>40.944178</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>34.947800</td>\n",
       "      <td>-88.722500</td>\n",
       "      <td>40.949474</td>\n",
       "      <td>42.408979</td>\n",
       "      <td>42.005750</td>\n",
       "      <td>3.364499</td>\n",
       "      <td>2.923830</td>\n",
       "      <td>2.695833</td>\n",
       "      <td>75.531629</td>\n",
       "      <td>75.868613</td>\n",
       "      <td>76.812834</td>\n",
       "      <td>168.8</td>\n",
       "      <td>42.2</td>\n",
       "      <td>18.1</td>\n",
       "      <td>0.194544</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2004</td>\n",
       "      <td>41.788067</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>39.641400</td>\n",
       "      <td>-119.308300</td>\n",
       "      <td>61.296741</td>\n",
       "      <td>66.193126</td>\n",
       "      <td>64.656615</td>\n",
       "      <td>4.054982</td>\n",
       "      <td>3.398329</td>\n",
       "      <td>3.671282</td>\n",
       "      <td>44.778429</td>\n",
       "      <td>37.140811</td>\n",
       "      <td>35.353846</td>\n",
       "      <td>10.4</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.487447</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2005</td>\n",
       "      <td>64.048828</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>30.904720</td>\n",
       "      <td>-93.557500</td>\n",
       "      <td>62.333490</td>\n",
       "      <td>62.596009</td>\n",
       "      <td>68.782609</td>\n",
       "      <td>1.331257</td>\n",
       "      <td>1.472949</td>\n",
       "      <td>1.424783</td>\n",
       "      <td>72.899478</td>\n",
       "      <td>75.061381</td>\n",
       "      <td>77.924623</td>\n",
       "      <td>28.4</td>\n",
       "      <td>27.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.241894</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2005</td>\n",
       "      <td>64.570703</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36530</th>\n",
       "      <td>0</td>\n",
       "      <td>37.606667</td>\n",
       "      <td>-96.422500</td>\n",
       "      <td>38.635038</td>\n",
       "      <td>37.471742</td>\n",
       "      <td>39.987614</td>\n",
       "      <td>5.100510</td>\n",
       "      <td>5.694737</td>\n",
       "      <td>4.975000</td>\n",
       "      <td>62.971774</td>\n",
       "      <td>69.376658</td>\n",
       "      <td>68.118919</td>\n",
       "      <td>20.1</td>\n",
       "      <td>18.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.365622</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>38.698132</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36531</th>\n",
       "      <td>0</td>\n",
       "      <td>40.394700</td>\n",
       "      <td>-104.564600</td>\n",
       "      <td>67.722291</td>\n",
       "      <td>66.728555</td>\n",
       "      <td>65.620761</td>\n",
       "      <td>2.507911</td>\n",
       "      <td>2.553364</td>\n",
       "      <td>2.638542</td>\n",
       "      <td>51.010341</td>\n",
       "      <td>50.264501</td>\n",
       "      <td>48.204861</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.199532</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>66.690536</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36532</th>\n",
       "      <td>0</td>\n",
       "      <td>39.180000</td>\n",
       "      <td>-96.784167</td>\n",
       "      <td>67.497438</td>\n",
       "      <td>62.404308</td>\n",
       "      <td>66.054190</td>\n",
       "      <td>3.259176</td>\n",
       "      <td>2.705398</td>\n",
       "      <td>3.196648</td>\n",
       "      <td>65.671410</td>\n",
       "      <td>61.839572</td>\n",
       "      <td>54.625698</td>\n",
       "      <td>35.4</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.331501</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2015</td>\n",
       "      <td>65.318645</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36533</th>\n",
       "      <td>1</td>\n",
       "      <td>37.262607</td>\n",
       "      <td>-119.511139</td>\n",
       "      <td>83.165726</td>\n",
       "      <td>83.165726</td>\n",
       "      <td>82.700000</td>\n",
       "      <td>2.649395</td>\n",
       "      <td>2.649395</td>\n",
       "      <td>2.667722</td>\n",
       "      <td>43.755556</td>\n",
       "      <td>43.755556</td>\n",
       "      <td>44.443975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097682</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>83.010484</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36534</th>\n",
       "      <td>0</td>\n",
       "      <td>38.843988</td>\n",
       "      <td>-122.759707</td>\n",
       "      <td>70.862404</td>\n",
       "      <td>70.362500</td>\n",
       "      <td>71.533571</td>\n",
       "      <td>1.795485</td>\n",
       "      <td>1.628065</td>\n",
       "      <td>1.036905</td>\n",
       "      <td>50.521912</td>\n",
       "      <td>46.310627</td>\n",
       "      <td>37.178571</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.167305</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.919492</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36535 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       stat_cause_descr   latitude   longitude  Temp_pre_30  Temp_pre_15  \\\n",
       "0                     0  18.105072  -66.753044    76.065753    76.490462   \n",
       "1                     1  35.038330  -87.610000    45.596180    44.618000   \n",
       "2                     1  34.947800  -88.722500    40.949474    42.408979   \n",
       "3                     2  39.641400 -119.308300    61.296741    66.193126   \n",
       "4                     3  30.904720  -93.557500    62.333490    62.596009   \n",
       "...                 ...        ...         ...          ...          ...   \n",
       "36530                 0  37.606667  -96.422500    38.635038    37.471742   \n",
       "36531                 0  40.394700 -104.564600    67.722291    66.728555   \n",
       "36532                 0  39.180000  -96.784167    67.497438    62.404308   \n",
       "36533                 1  37.262607 -119.511139    83.165726    83.165726   \n",
       "36534                 0  38.843988 -122.759707    70.862404    70.362500   \n",
       "\n",
       "       Temp_pre_7  Wind_pre_30  Wind_pre_15  Wind_pre_7  Hum_pre_30  \\\n",
       "0       76.824675     4.341807     3.492857    3.262092   78.216590   \n",
       "1       32.618353     2.709764     2.881707    1.976471   70.840000   \n",
       "2       42.005750     3.364499     2.923830    2.695833   75.531629   \n",
       "3       64.656615     4.054982     3.398329    3.671282   44.778429   \n",
       "4       68.782609     1.331257     1.472949    1.424783   72.899478   \n",
       "...           ...          ...          ...         ...         ...   \n",
       "36530   39.987614     5.100510     5.694737    4.975000   62.971774   \n",
       "36531   65.620761     2.507911     2.553364    2.638542   51.010341   \n",
       "36532   66.054190     3.259176     2.705398    3.196648   65.671410   \n",
       "36533   82.700000     2.649395     2.649395    2.667722   43.755556   \n",
       "36534   71.533571     1.795485     1.628065    1.036905   50.521912   \n",
       "\n",
       "       Hum_pre_15  Hum_pre_7  Prec_pre_30  Prec_pre_15  Prec_pre_7  \\\n",
       "0       76.793750  76.381579          0.0          0.0         0.0   \n",
       "1       65.858911  55.505882         59.8          8.4         0.0   \n",
       "2       75.868613  76.812834        168.8         42.2        18.1   \n",
       "3       37.140811  35.353846         10.4          7.2         0.0   \n",
       "4       75.061381  77.924623         28.4         27.5         1.2   \n",
       "...           ...        ...          ...          ...         ...   \n",
       "36530   69.376658  68.118919         20.1         18.8         0.0   \n",
       "36531   50.264501  48.204861          4.6          0.0         0.0   \n",
       "36532   61.839572  54.625698         35.4          8.2         0.0   \n",
       "36533   43.755556  44.443975          0.0          0.0         0.0   \n",
       "36534   46.310627  37.178571          0.3          0.3         0.0   \n",
       "\n",
       "       remoteness  target  month  year   temp_avg  is_remote  did_rain  \\\n",
       "0        0.017923       0      2  2007  76.460297          0         0   \n",
       "1        0.184355       0     12  2006  40.944178          0         1   \n",
       "2        0.194544       0      2  2004  41.788067          0         1   \n",
       "3        0.487447       0      6  2005  64.048828          0         1   \n",
       "4        0.241894       0     11  2005  64.570703          0         1   \n",
       "...           ...     ...    ...   ...        ...        ...       ...   \n",
       "36530    0.365622       1      2  2015  38.698132          0         1   \n",
       "36531    0.199532       1      9  2015  66.690536          0         1   \n",
       "36532    0.331501       1     10  2015  65.318645          0         1   \n",
       "36533    0.097682       1      7  2015  83.010484          0         0   \n",
       "36534    0.167305       1      9  2015  70.919492          0         1   \n",
       "\n",
       "       Temp_pre_30_bin  Temp_pre_15_bin  Temp_pre_7_bin  discovery_month_Aug  \\\n",
       "0                    3                3               3                    0   \n",
       "1                    0                0               0                    0   \n",
       "2                    0                0               0                    0   \n",
       "3                    2                2               2                    0   \n",
       "4                    2                2               2                    0   \n",
       "...                ...              ...             ...                  ...   \n",
       "36530                0                0               0                    0   \n",
       "36531                2                2               2                    0   \n",
       "36532                2                2               2                    0   \n",
       "36533                3                3               3                    0   \n",
       "36534                2                2               2                    0   \n",
       "\n",
       "       discovery_month_Dec  discovery_month_Feb  discovery_month_Jan  \\\n",
       "0                        0                    1                    0   \n",
       "1                        1                    0                    0   \n",
       "2                        0                    1                    0   \n",
       "3                        0                    0                    0   \n",
       "4                        0                    0                    0   \n",
       "...                    ...                  ...                  ...   \n",
       "36530                    0                    1                    0   \n",
       "36531                    0                    0                    0   \n",
       "36532                    0                    0                    0   \n",
       "36533                    0                    0                    0   \n",
       "36534                    0                    0                    0   \n",
       "\n",
       "       discovery_month_Jul  discovery_month_Jun  discovery_month_Mar  \\\n",
       "0                        0                    0                    0   \n",
       "1                        0                    0                    0   \n",
       "2                        0                    0                    0   \n",
       "3                        0                    1                    0   \n",
       "4                        0                    0                    0   \n",
       "...                    ...                  ...                  ...   \n",
       "36530                    0                    0                    0   \n",
       "36531                    0                    0                    0   \n",
       "36532                    0                    0                    0   \n",
       "36533                    1                    0                    0   \n",
       "36534                    0                    0                    0   \n",
       "\n",
       "       discovery_month_May  discovery_month_Nov  discovery_month_Oct  \\\n",
       "0                        0                    0                    0   \n",
       "1                        0                    0                    0   \n",
       "2                        0                    0                    0   \n",
       "3                        0                    0                    0   \n",
       "4                        0                    1                    0   \n",
       "...                    ...                  ...                  ...   \n",
       "36530                    0                    0                    0   \n",
       "36531                    0                    0                    0   \n",
       "36532                    0                    0                    1   \n",
       "36533                    0                    0                    0   \n",
       "36534                    0                    0                    0   \n",
       "\n",
       "       discovery_month_Sep  state_AL  state_AR  state_AZ  state_CA  state_CO  \\\n",
       "0                        0         0         0         0         0         0   \n",
       "1                        0         0         0         0         0         0   \n",
       "2                        0         0         0         0         0         0   \n",
       "3                        0         0         0         0         0         0   \n",
       "4                        0         0         0         0         0         0   \n",
       "...                    ...       ...       ...       ...       ...       ...   \n",
       "36530                    0         0         0         0         0         0   \n",
       "36531                    1         0         0         0         0         1   \n",
       "36532                    0         0         0         0         0         0   \n",
       "36533                    0         0         0         0         1         0   \n",
       "36534                    1         0         0         0         1         0   \n",
       "\n",
       "       state_CT  state_DE  state_FL  state_GA  state_HI  state_IA  state_ID  \\\n",
       "0             0         0         0         0         0         0         0   \n",
       "1             0         0         0         0         0         0         0   \n",
       "2             0         0         0         0         0         0         0   \n",
       "3             0         0         0         0         0         0         0   \n",
       "4             0         0         0         0         0         0         0   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "36530         0         0         0         0         0         0         0   \n",
       "36531         0         0         0         0         0         0         0   \n",
       "36532         0         0         0         0         0         0         0   \n",
       "36533         0         0         0         0         0         0         0   \n",
       "36534         0         0         0         0         0         0         0   \n",
       "\n",
       "       state_IL  state_IN  state_KS  state_KY  state_LA  state_MA  state_MD  \\\n",
       "0             0         0         0         0         0         0         0   \n",
       "1             0         0         0         0         0         0         0   \n",
       "2             0         0         0         0         0         0         0   \n",
       "3             0         0         0         0         0         0         0   \n",
       "4             0         0         0         0         0         0         0   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "36530         0         0         1         0         0         0         0   \n",
       "36531         0         0         0         0         0         0         0   \n",
       "36532         0         0         1         0         0         0         0   \n",
       "36533         0         0         0         0         0         0         0   \n",
       "36534         0         0         0         0         0         0         0   \n",
       "\n",
       "       state_ME  state_MI  state_MN  state_MO  state_MS  state_MT  state_NC  \\\n",
       "0             0         0         0         0         0         0         0   \n",
       "1             0         0         0         0         0         0         0   \n",
       "2             0         0         0         0         1         0         0   \n",
       "3             0         0         0         0         0         0         0   \n",
       "4             0         0         0         0         0         0         0   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "36530         0         0         0         0         0         0         0   \n",
       "36531         0         0         0         0         0         0         0   \n",
       "36532         0         0         0         0         0         0         0   \n",
       "36533         0         0         0         0         0         0         0   \n",
       "36534         0         0         0         0         0         0         0   \n",
       "\n",
       "       state_ND  state_NE  state_NH  state_NJ  state_NM  state_NV  state_NY  \\\n",
       "0             0         0         0         0         0         0         0   \n",
       "1             0         0         0         0         0         0         0   \n",
       "2             0         0         0         0         0         0         0   \n",
       "3             0         0         0         0         0         1         0   \n",
       "4             0         0         0         0         0         0         0   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "36530         0         0         0         0         0         0         0   \n",
       "36531         0         0         0         0         0         0         0   \n",
       "36532         0         0         0         0         0         0         0   \n",
       "36533         0         0         0         0         0         0         0   \n",
       "36534         0         0         0         0         0         0         0   \n",
       "\n",
       "       state_OH  state_OK  state_OR  state_PA  state_PR  state_RI  state_SC  \\\n",
       "0             0         0         0         0         1         0         0   \n",
       "1             0         0         0         0         0         0         0   \n",
       "2             0         0         0         0         0         0         0   \n",
       "3             0         0         0         0         0         0         0   \n",
       "4             0         0         0         0         0         0         0   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "36530         0         0         0         0         0         0         0   \n",
       "36531         0         0         0         0         0         0         0   \n",
       "36532         0         0         0         0         0         0         0   \n",
       "36533         0         0         0         0         0         0         0   \n",
       "36534         0         0         0         0         0         0         0   \n",
       "\n",
       "       state_SD  state_TN  state_TX  state_UT  state_VA  state_VT  state_WA  \\\n",
       "0             0         0         0         0         0         0         0   \n",
       "1             0         1         0         0         0         0         0   \n",
       "2             0         0         0         0         0         0         0   \n",
       "3             0         0         0         0         0         0         0   \n",
       "4             0         0         1         0         0         0         0   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "36530         0         0         0         0         0         0         0   \n",
       "36531         0         0         0         0         0         0         0   \n",
       "36532         0         0         0         0         0         0         0   \n",
       "36533         0         0         0         0         0         0         0   \n",
       "36534         0         0         0         0         0         0         0   \n",
       "\n",
       "       state_WI  state_WV  state_WY  Vegetation_4  Vegetation_9  \\\n",
       "0             0         0         0             0             0   \n",
       "1             0         0         0             0             0   \n",
       "2             0         0         0             0             0   \n",
       "3             0         0         0             0             0   \n",
       "4             0         0         0             0             0   \n",
       "...         ...       ...       ...           ...           ...   \n",
       "36530         0         0         0             0             0   \n",
       "36531         0         0         0             0             0   \n",
       "36532         0         0         0             0             0   \n",
       "36533         0         0         0             0             0   \n",
       "36534         0         0         0             0             0   \n",
       "\n",
       "       Vegetation_12  Vegetation_14  Vegetation_15  Vegetation_16  \\\n",
       "0                  1              0              0              0   \n",
       "1                  0              0              1              0   \n",
       "2                  0              0              0              1   \n",
       "3                  0              0              0              0   \n",
       "4                  1              0              0              0   \n",
       "...              ...            ...            ...            ...   \n",
       "36530              0              0              0              0   \n",
       "36531              0              1              0              0   \n",
       "36532              0              0              0              0   \n",
       "36533              0              0              0              0   \n",
       "36534              0              0              0              0   \n",
       "\n",
       "       longitude_bin  west_coast  very_windy_30  very_windy_15  very_windy_7  \\\n",
       "0                  3           0              1              1             1   \n",
       "1                  2           0              0              0             0   \n",
       "2                  2           0              0              0             0   \n",
       "3                  0           1              1              1             1   \n",
       "4                  1           0              0              0             0   \n",
       "...              ...         ...            ...            ...           ...   \n",
       "36530              1           0              1              1             1   \n",
       "36531              1           1              0              0             0   \n",
       "36532              1           0              0              0             0   \n",
       "36533              0           1              0              0             0   \n",
       "36534              0           1              0              0             0   \n",
       "\n",
       "       low_humid_30  low_humid_15  low_humid_7  \n",
       "0                 0             0            0  \n",
       "1                 0             0            0  \n",
       "2                 0             0            0  \n",
       "3                 1             1            1  \n",
       "4                 0             0            0  \n",
       "...             ...           ...          ...  \n",
       "36530             0             0            0  \n",
       "36531             0             0            1  \n",
       "36532             0             0            0  \n",
       "36533             1             1            1  \n",
       "36534             0             1            1  \n",
       "\n",
       "[36535 rows x 100 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Feature data frame and Target data frame\n",
    "X = df.drop(columns='target',axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Creating Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Scaling is Needed for Knn\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All 3 of the below models use basic parameters to give baseline information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogRegTest(input_x,input_y):\n",
    "    lr = LogisticRegression(random_state=1,C=1e9)\n",
    "    lr.fit(input_x,input_y)\n",
    "    pred_train = lr.predict(input_x)\n",
    "    score = f1_score(input_y,pred_train,zero_division=1)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KnnTest(input_x,input_y):\n",
    "    knn = KNeighborsClassifier(n_neighbors=5,algorithm='auto',weights='uniform')\n",
    "    knn.fit(input_x,input_y)\n",
    "    pred_train = knn.predict(input_x)\n",
    "    score = f1_score(input_y,pred_train,zero_division=1)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DTreeTest(input_x,input_y):\n",
    "    tree = DecisionTreeClassifier(max_depth=12, min_samples_split=17,criterion='gini',min_samples_leaf=4)\n",
    "    tree.fit(input_x,input_y)\n",
    "    pred_train = tree.predict(input_x)\n",
    "    score = f1_score(input_y,pred_train,zero_division=1)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_class_test(X_train,y_train):\n",
    "    print('LogReg F1: ', LogRegTest(X_train,y_train))\n",
    "    print('Knn F1: ', KnnTest(X_train,y_train))\n",
    "    print('Dtree F1: ', DTreeTest(X_train,y_train))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline with Test Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.5090425924558943\n",
      "Test:  0.5229330996202162\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression(random_state=2,C=1e9,class_weight='balanced',penalty='l2')\n",
    "\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "pred_train = lr.predict(X_train)\n",
    "\n",
    "pred_test = lr.predict(X_test)\n",
    "\n",
    "score_train = f1_score(y_train,pred_train)\n",
    "score_test = f1_score(y_test,pred_test)\n",
    "\n",
    "print('Train: ',score_train)\n",
    "print('Test: ',score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.5090425924558943\n",
      "Test:  0.5229330996202162\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=5,algorithm='auto',weights='uniform')\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = knn.predict(X_train)\n",
    "\n",
    "y_pred_test = knn.predict(X_test)\n",
    "\n",
    "score_train = f1_score(y_train,pred_train)\n",
    "score_test = f1_score(y_test,pred_test)\n",
    "\n",
    "print('Train: ',score_train)\n",
    "print('Test: ',score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.8443716947872073\n",
      "Test:  0.815354713313897\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "tree = DecisionTreeClassifier(max_depth=12, min_samples_split=17,criterion='gini',min_samples_leaf=4)\n",
    "\n",
    "tree = tree.fit(X_train,y_train)\n",
    "\n",
    "pred_train = tree.predict(X_train)\n",
    "\n",
    "pred_test = tree.predict(X_test)\n",
    "\n",
    "score_train = f1_score(y_train,pred_train)\n",
    "score_test = f1_score(y_test,pred_test)\n",
    "\n",
    "print('Train: ',score_train)\n",
    "print('Test: ',score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state = 99, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Method Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2, f_classif, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# instantiating a feature selector object\n",
    "feature_selector = SelectKBest(mutual_info_classif,15)\n",
    "\n",
    "# fitting to our data\n",
    "feature_selector.fit(X_train,y_train)\n",
    "\n",
    "# features that we keep\n",
    "selected_filter = X_train.columns[feature_selector.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg F1:  0.4008607439286812\n",
      "Knn F1:  0.6587261785356069\n",
      "Dtree F1:  0.835092180546726\n"
     ]
    }
   ],
   "source": [
    "three_class_test(X_train[selected_filter],y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using Logistic Regression as the estimation of 'goodness'\n",
    "estimator = LogisticRegression()\n",
    "# creating a selector object\n",
    "feature_selector = RFECV(estimator=estimator, step=1, cv=5,n_jobs=-1,min_features_to_select=8)\n",
    "# fitting to our data\n",
    "feature_selector.fit(X_train, y_train)\n",
    "# Extracting most important features\n",
    "selected_wrapper = X_train.columns[feature_selector.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg F1:  0.6067575241340147\n",
      "Knn F1:  0.8102432778489118\n",
      "Dtree F1:  0.8155567117585848\n"
     ]
    }
   ],
   "source": [
    "three_class_test(X_train[selected_wrapper],y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='target',axis=1)\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state = 99, test_size=0.2)\n",
    "\n",
    "X_train = X_train[selected_wrapper]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Imbalance Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsampling using reampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolating training data\n",
    "training = pd.concat([X_train,y_train],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting by target value\n",
    "large = training[training.target == 1]\n",
    "small = training[training.target == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "large count: 4512\n",
      "small count: 24716\n"
     ]
    }
   ],
   "source": [
    "print('large count: '+ str(len(large)))\n",
    "print('small count: '+ str(len(small)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of upsampled large:  24716\n"
     ]
    }
   ],
   "source": [
    "# upsampling with replacement to match majority class size\n",
    "large_upsampled = resample(large,\n",
    "                        replace=True,\n",
    "                        n_samples=len(small),\n",
    "                        random_state=99)\n",
    "print('Size of upsampled large: ',len(large_upsampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining back together\n",
    "upsampled = pd.concat([small,large_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating training data\n",
    "X_train_upsample = upsampled.drop(columns='target')\n",
    "y_train_upsample = upsampled.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Over-sampling SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating synthetic rows using SMOTE\n",
    "sm = SMOTE(random_state=99)\n",
    "X_train_smote, y_train_smote = sm.fit_sample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_smote_rfe, y_train_smote_rfe = sm.fit_sample(X_train[selected_wrapper],y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_downsampled = resample(small,\n",
    "                            replace = False,\n",
    "                            n_samples=len(small),\n",
    "                            random_state=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled = pd.concat([small_downsampled,large])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_downsample = downsampled.drop(columns='target')\n",
    "y_train_downsample = downsampled.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tomek Links DownSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from imblearn.under_sampling import TomekLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({0: 23923, 1: 4512})\n"
     ]
    }
   ],
   "source": [
    "tl = TomekLinks()\n",
    "X_res, y_res = tl.fit_resample(X_train, y_train)\n",
    "print('Resampled dataset shape %s' % Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove Tomek links\n",
    "tl = TomekLinks()\n",
    "X_train_tomek, y_train_tomek = tl.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Smote and Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg F1:  0.783974229917455\n",
      "Knn F1:  0.9549129353233831\n",
      "Dtree F1:  0.8856682769726247\n"
     ]
    }
   ],
   "source": [
    "# Upsampling\n",
    "three_class_test(X_train_upsample[selected_wrapper],y_train_upsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg F1:  0.7909290475902765\n",
      "Knn F1:  0.9107224083033536\n",
      "Dtree F1:  0.8760022848922081\n"
     ]
    }
   ],
   "source": [
    "# SMOTE\n",
    "three_class_test(X_train_smote[selected_wrapper],y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg F1:  0.6067575241340147\n",
      "Knn F1:  0.8103955959544232\n",
      "Dtree F1:  0.8155567117585848\n"
     ]
    }
   ],
   "source": [
    "# Normal Downsampling\n",
    "three_class_test(X_train_downsample[selected_wrapper],y_train_downsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg F1:  0.6118658164679789\n",
      "Knn F1:  0.8221044663133988\n",
      "Dtree F1:  0.8222250870181771\n"
     ]
    }
   ],
   "source": [
    "# Tomek Links downsampling\n",
    "three_class_test(X_train_tomek[selected_wrapper],y_train_tomek)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can see that upsamping and smote are the best method for dealing with class imbalance. Smote will be used from now on as we want a very interpretable model so we care more about logistic regression and decision tree scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Feature Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Train Test split using selected balancing and features\n",
    "X_train_selected = X_train_smote\n",
    "y_train_selected = y_train_smote\n",
    "\n",
    "X_test_selected = X_test[selected_wrapper]\n",
    "y_test_selected = y_test\n",
    "\n",
    "# Scaling is Needed for Knn\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train_selected)\n",
    "\n",
    "X_train_selected = scaler.transform(X_train_selected)  \n",
    "X_test_selected = scaler.transform(X_test_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.7908644163377105\n",
      "Test:  0.5381574946792338\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression(random_state=10,C=1,penalty='l2',max_iter=1000)\n",
    "\n",
    "lr.fit(X_train_selected,y_train_selected)\n",
    "\n",
    "pred_train = lr.predict(X_train_selected)\n",
    "\n",
    "pred_test = lr.predict(X_test_selected)\n",
    "\n",
    "score_train = f1_score(y_train_selected,pred_train)\n",
    "score_test = f1_score(y_test_selected,pred_test)\n",
    "\n",
    "print('Train: ',score_train)\n",
    "print('Test: ',score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.9107227794436976\n",
      "Test:  0.6804915514592934\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=5,algorithm='auto',weights='uniform')\n",
    "\n",
    "knn.fit(X_train_selected, y_train_selected)\n",
    "\n",
    "y_pred_train = knn.predict(X_train_selected)\n",
    "\n",
    "y_pred_test = knn.predict(X_test_selected)\n",
    "\n",
    "score_train = f1_score(y_train_selected,y_pred_train)\n",
    "score_test = f1_score(y_test_selected,y_pred_test)\n",
    "\n",
    "print('Train: ',score_train)\n",
    "print('Test: ',score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.861164101911908\n",
      "Test:  0.7099767981438515\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "tree = DecisionTreeClassifier(max_depth=9, min_samples_leaf=10, min_samples_split=5,)\n",
    "\n",
    "tree = tree.fit(X_train_selected,y_train_selected)\n",
    "\n",
    "pred_train = tree.predict(X_train_selected)\n",
    "\n",
    "pred_test = tree.predict(X_test_selected)\n",
    "\n",
    "score_train = f1_score(y_train_selected,pred_train)\n",
    "score_test = f1_score(y_test,pred_test)\n",
    "\n",
    "print('Train: ',score_train)\n",
    "print('Test: ',score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'penalty': ['l2'],\n",
    "    'C': [0.1,0.05,],\n",
    "    'max_iter':[1000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  20 | elapsed:    1.5s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': [0.1, 0.05], 'max_iter': [1000],\n",
       "                         'penalty': ['l2']},\n",
       "             scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_log=GridSearchCV(LogisticRegression(),\n",
    "                         param_grid, \n",
    "                         cv=10, \n",
    "                         scoring='f1', \n",
    "                         verbose=1, \n",
    "                         n_jobs=-1)\n",
    "\n",
    "grid_log.fit(X_train_selected,y_train_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7904544701575759\n",
      "{'C': 0.05, 'max_iter': 1000, 'penalty': 'l2'}\n",
      "LogisticRegression(C=0.05, max_iter=1000)\n"
     ]
    }
   ],
   "source": [
    "# Single best score achieved across all params (min_samples_split)\n",
    "print(grid_log.best_score_)\n",
    "\n",
    "# Dictionary containing the parameters (min_samples_split) used to generate that score\n",
    "print(grid_log.best_params_)\n",
    "\n",
    "# Actual model object fit with those best parameters\n",
    "# Shows default parameters that we did not specify\n",
    "print(grid_log.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.897359\n",
      "F1: 0.709977\n",
      "Recall: 0.824057\n",
      "Precision: 0.623641\n"
     ]
    }
   ],
   "source": [
    "#Predict the response for test dataset\n",
    "y_pred_test = grid_log.best_estimator_.predict(X_test_selected)\n",
    "\n",
    "y_pred_train = grid_log.best_estimator_.predict(X_train_selected)\n",
    "\n",
    "\n",
    "test_f1 = f1_score(y_test_selected, pred_test)\n",
    "test_acc = accuracy_score(y_test_selected, pred_test)\n",
    "test_recall = recall_score(y_test_selected, pred_test)\n",
    "test_precision = precision_score(y_test_selected,pred_test)\n",
    "\n",
    "print(\"Accuracy: %f\" % (test_acc))\n",
    "print(\"F1: %f\" % (test_f1))\n",
    "print(\"Recall: %f\" % (test_recall))\n",
    "print('Precision: %f' % (test_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid={\n",
    "    'criterion': ['gini'],\n",
    "    'max_depth': range(3,10,1),\n",
    "    'min_samples_split': range(1,5,1),\n",
    "    'min_samples_leaf': range(1,5,1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 112 candidates, totalling 1120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   30.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1120 out of 1120 | elapsed:   48.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini'], 'max_depth': range(3, 10),\n",
       "                         'min_samples_leaf': range(1, 5),\n",
       "                         'min_samples_split': range(1, 5)},\n",
       "             scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_tree=GridSearchCV(DecisionTreeClassifier(),\n",
    "                         param_grid, \n",
    "                         cv=10, \n",
    "                         scoring='f1', \n",
    "                         verbose=1, \n",
    "                         n_jobs=-1)\n",
    "\n",
    "grid_tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.808823189968425\n",
      "{'criterion': 'gini', 'max_depth': 9, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "DecisionTreeClassifier(max_depth=9, min_samples_leaf=2)\n"
     ]
    }
   ],
   "source": [
    "# Single best score achieved across all params (min_samples_split)\n",
    "print(grid_tree.best_score_)\n",
    "\n",
    "# Dictionary containing the parameters (min_samples_split) used to generate that score\n",
    "print(grid_tree.best_params_)\n",
    "\n",
    "# Actual model object fit with those best parameters\n",
    "# Shows default parameters that we did not specify\n",
    "print(grid_tree.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=13, max_leaf_nodes=40,random_state=80)\n",
    "\n",
    "tree = tree.fit(X_train,y_train)\n",
    "\n",
    "pred_train = tree.predict(X_train)\n",
    "\n",
    "pred_test = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.954838\n",
      "F1: 0.828482\n",
      "Recall: 0.715440\n",
      "Precision: 0.983951\n"
     ]
    }
   ],
   "source": [
    "test_f1 = f1_score(y_test,pred_test)\n",
    "test_acc = accuracy_score(y_test, pred_test)\n",
    "test_recall = recall_score(y_test, pred_test)\n",
    "test_precision = precision_score(y_test,pred_test)\n",
    "\n",
    "print(\"Accuracy: %f\" % (test_acc))\n",
    "print(\"F1: %f\" % (test_f1))\n",
    "print(\"Recall: %f\" % (test_recall))\n",
    "print('Precision: %f' % (test_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1:' + str(metrics.f1_score(y_train, pred_train)))\n",
    "print('F1:' + str(metrics.f1_score(y_test, pred_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XG BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error,accuracy_score, f1_score, roc_auc_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This includes max_depth, min_child_weight and gamma.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_clf = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                           colsample_bytree = 0.5, \n",
    "                           min_child_weight = 5,\n",
    "                           learning_rate = 0.1,\n",
    "                           max_depth = 5, \n",
    "                           n_estimators = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(colsample_bytree=0.5, max_depth=5, min_child_weight=5,\n",
       "              n_estimators=500)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_clf.fit(X_train_selected,y_train_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.939099\n",
      "F1: 0.788599\n",
      "Recall: 0.745063\n",
      "Precision: 0.837538\n"
     ]
    }
   ],
   "source": [
    "preds = xg_clf.predict(X_test_selected)\n",
    "\n",
    "test_f1 = f1_score(y_test_selected, preds)\n",
    "test_acc = accuracy_score(y_test_selected, preds)\n",
    "test_recall = recall_score(y_test_selected, preds)\n",
    "test_precision = precision_score(y_test_selected,preds)\n",
    "\n",
    "print(\"Accuracy: %f\" % (test_acc))\n",
    "print(\"F1: %f\" % (test_f1))\n",
    "print(\"Recall: %f\" % (test_recall))\n",
    "print('Precision: %f' % (test_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb.plot_importance(xg_clf,max_num_features = 15)\n",
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Searched XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb = xgb.XGBClassifier(objective = 'binary:logistic')\n",
    "param_dist = {'n_estimators': [100,300,500],\n",
    "              'learning_rate': [0.1,0.07,0.05,0.03,0.01],\n",
    "              'max_depth': [3, 4, 5, 6, 7],\n",
    "              'colsample_bytree': [0.5,0.45,0.4],\n",
    "              'min_child_weight': [1, 2, 3]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate the Gridsearch model\n",
    "gsearch1 = GridSearchCV(\n",
    "    estimator = clf_xgb,\n",
    "    param_grid = param_dist, \n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    iid=False, \n",
    "    cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 675 candidates, totalling 3375 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed: 25.0min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed: 44.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed: 71.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed: 103.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2426 tasks      | elapsed: 138.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3176 tasks      | elapsed: 179.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3375 out of 3375 | elapsed: 191.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=XGBClassifier(), iid=False, n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [0.5, 0.45, 0.4],\n",
       "                         'learning_rate': [0.1, 0.07, 0.05, 0.03, 0.01],\n",
       "                         'max_depth': [3, 4, 5, 6, 7],\n",
       "                         'min_child_weight': [1, 2, 3],\n",
       "                         'n_estimators': [100, 300, 500]},\n",
       "             scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.fit(X_train_smote[selected_wrapper],y_train_smote)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.5,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 7,\n",
       " 'min_child_weight': 2,\n",
       " 'n_estimators': 500}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.938353211318369"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These hyperparameters will be used in the XGBoost above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some info about xgboost:\n",
    "* Generally, importance provides a score that indicates how useful or valuable each feature was in the construction of the boosted decision trees within the model. The more an attribute is used to make key decisions with decision trees, the higher its relative importance.\n",
    "* Importance is calculated for a single decision tree by the amount that each attribute split point improves the performance measure, weighted by the number of observations the node is responsible for. The performance measure may be the purity (Gini index) used to select the split points or another more specific error function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
